}
if (.Platform$OS.type=="unix") {
setwd("~/Dropbox/StatsBook6")
} else {# on a windows computer
setwd("C:/Users/xt8b/Dropbox/StatsBook6")
}
library(stringi)
# Only strips comments that start at the beginning of
# the line (other than spacing)
# If we try to delete mid-line LaTeX comments, we run into the problem
# of removing code like "%>%" and "%in%", which are important to keep.
# That said, I'm assuming code blocks that are commented out don't have
# LaTeX comments at the end of lines, and other LaTeX comments are
# being removed with the rest of the text anyway, so we don't need
# to worry about removing mid-line comments here
stripLaTeXComments <- function(vect){
vect <- stri_replace_all_regex(vect,"^\\s*%.*","")
return(vect)
}
extractRChunks <- function(filename, includeCommentedChunks = TRUE){
tempFileStrings <- readLines(paste0("chapters/",filename, ".Rnw"))
commentedChunkNames <- ""
if(!includeCommentedChunks){
tempFileStrings <- stripLaTeXComments(tempFileStrings)
commentedChunkNames <- "NoCommentedChunks_"
}
beginChunkLines <- stri_detect(tempFileStrings, regex = "<<.*>>=")
endChunkLines <- stri_detect(tempFileStrings, regex = "\\s*@\\s*$")
if(sum(beginChunkLines)!=sum(endChunkLines)){
stop("Number of detected chunk beginnings different than number of detected chunk endings.")
} else if(sum(beginChunkLines) > 0){
chunkLinePairs <- cbind(which(beginChunkLines),which(endChunkLines))
sink(paste0("extractRChunks/RChunks/",commentedChunkNames, filename, "_RChunks",".R"))
for(i in 1:nrow(chunkLinePairs)){
chunkLabel <- stri_replace_all_regex(tempFileStrings[chunkLinePairs[i,1]],"<<(.*),.*>>=","$1")
cat("##",chunkLabel)
cat("\n\n")
for(j in chunkLinePairs[i,1]:chunkLinePairs[i,2]){
cat(tempFileStrings[j])
cat("\n")
}
cat("\n\n")
}
sink()
} else {
message("No detected R chunks in ",filename,".Rnw. Aborting.")
}
}
chapterNames <- list.files("chapters", pattern="Rnw")
chapterNames <- stri_replace_all_fixed(chapterNames, ".Rnw", "")
for(i in chapterNames){
extractRChunks(i, includeCommentedChunks = FALSE)
extractRChunks(i, includeCommentedChunks = TRUE)
}
if (.Platform$OS.type=="unix") {
setwd("~/Dropbox/StatsBook6")
} else {# on a windows computer
setwd("C:/Users/xt8b/Dropbox/StatsBook6")
}
library(stringi)
# Only strips comments that start at the beginning of
# the line (other than spacing)
# If we try to delete mid-line LaTeX comments, we run into the problem
# of removing code like "%>%" and "%in%", which are important to keep.
# That said, I'm assuming code blocks that are commented out don't have
# LaTeX comments at the end of lines, and other LaTeX comments are
# being removed with the rest of the text anyway, so we don't need
# to worry about removing mid-line comments here
stripLaTeXComments <- function(vect){
vect <- stri_replace_all_regex(vect,"^\\s*%.*","")
return(vect)
}
extractRChunks <- function(filename, includeCommentedChunks = TRUE){
tempFileStrings <- readLines(paste0("chapters/",filename, ".Rnw"))
commentedChunkNames <- ""
if(!includeCommentedChunks){
tempFileStrings <- stripLaTeXComments(tempFileStrings)
commentedChunkNames <- "NoCommentedChunks_"
}
beginChunkLines <- stri_detect(tempFileStrings, regex = "<<.*>>=")
endChunkLines <- stri_detect(tempFileStrings, regex = "\\s*@\\s*$")
if(sum(beginChunkLines)!=sum(endChunkLines)){
stop("Number of detected chunk beginnings different than number of detected chunk endings.")
} else if(sum(beginChunkLines) > 0){
chunkLinePairs <- cbind(which(beginChunkLines),which(endChunkLines))
sink(paste0("extractRChunks/RChunks/",commentedChunkNames, filename, "_RChunks",".R"))
for(i in 1:nrow(chunkLinePairs)){
chunkLabel <- stri_replace_all_regex(tempFileStrings[chunkLinePairs[i,1]],"<<(.+?),.*>>=","$1")
cat("##",chunkLabel)
cat("\n\n")
for(j in chunkLinePairs[i,1]:chunkLinePairs[i,2]){
cat(tempFileStrings[j])
cat("\n")
}
cat("\n\n")
}
sink()
} else {
message("No detected R chunks in ",filename,".Rnw. Aborting.")
}
}
chapterNames <- list.files("chapters", pattern="Rnw")
chapterNames <- stri_replace_all_fixed(chapterNames, ".Rnw", "")
for(i in chapterNames){
extractRChunks(i, includeCommentedChunks = FALSE)
extractRChunks(i, includeCommentedChunks = TRUE)
}
if (.Platform$OS.type=="unix") {
setwd("~/Dropbox/StatsBook6")
} else {# on a windows computer
setwd("C:/Users/xt8b/Dropbox/StatsBook6")
}
library(stringi)
# Only strips comments that start at the beginning of
# the line (other than spacing)
# If we try to delete mid-line LaTeX comments, we run into the problem
# of removing code like "%>%" and "%in%", which are important to keep.
# That said, I'm assuming code blocks that are commented out don't have
# LaTeX comments at the end of lines, and other LaTeX comments are
# being removed with the rest of the text anyway, so we don't need
# to worry about removing mid-line comments here
stripLaTeXComments <- function(vect){
vect <- stri_replace_all_regex(vect,"^\\s*%.*","")
return(vect)
}
extractRChunks <- function(filename, includeCommentedChunks = TRUE){
tempFileStrings <- readLines(paste0("chapters/",filename, ".Rnw"))
commentedChunkNames <- ""
if(!includeCommentedChunks){
tempFileStrings <- stripLaTeXComments(tempFileStrings)
commentedChunkNames <- "NoCommentedChunks_"
}
beginChunkLines <- stri_detect(tempFileStrings, regex = "<<.*>>=")
endChunkLines <- stri_detect(tempFileStrings, regex = "\\s*@\\s*$")
if(sum(beginChunkLines)!=sum(endChunkLines)){
stop("Number of detected chunk beginnings different than number of detected chunk endings.")
} else if(sum(beginChunkLines) > 0){
chunkLinePairs <- cbind(which(beginChunkLines),which(endChunkLines))
sink(paste0("extractRChunks/RChunks/",commentedChunkNames, filename, "_RChunks",".R"))
for(i in 1:nrow(chunkLinePairs)){
chunkLabel <- stri_replace_all_regex(tempFileStrings[chunkLinePairs[i,1]],"(% ?)?<<(.+?),.*>>=","$1")
cat("##",chunkLabel)
cat("\n\n")
for(j in chunkLinePairs[i,1]:chunkLinePairs[i,2]){
cat(tempFileStrings[j])
cat("\n")
}
cat("\n\n")
}
sink()
} else {
message("No detected R chunks in ",filename,".Rnw. Aborting.")
}
}
chapterNames <- list.files("chapters", pattern="Rnw")
chapterNames <- stri_replace_all_fixed(chapterNames, ".Rnw", "")
for(i in chapterNames){
extractRChunks(i, includeCommentedChunks = FALSE)
extractRChunks(i, includeCommentedChunks = TRUE)
}
if (.Platform$OS.type=="unix") {
setwd("~/Dropbox/StatsBook6")
} else {# on a windows computer
setwd("C:/Users/xt8b/Dropbox/StatsBook6")
}
library(stringi)
# Only strips comments that start at the beginning of
# the line (other than spacing)
# If we try to delete mid-line LaTeX comments, we run into the problem
# of removing code like "%>%" and "%in%", which are important to keep.
# That said, I'm assuming code blocks that are commented out don't have
# LaTeX comments at the end of lines, and other LaTeX comments are
# being removed with the rest of the text anyway, so we don't need
# to worry about removing mid-line comments here
stripLaTeXComments <- function(vect){
vect <- stri_replace_all_regex(vect,"^\\s*%.*","")
return(vect)
}
extractRChunks <- function(filename, includeCommentedChunks = TRUE){
tempFileStrings <- readLines(paste0("chapters/",filename, ".Rnw"))
commentedChunkNames <- ""
if(!includeCommentedChunks){
tempFileStrings <- stripLaTeXComments(tempFileStrings)
commentedChunkNames <- "NoCommentedChunks_"
}
beginChunkLines <- stri_detect(tempFileStrings, regex = "<<.*>>=")
endChunkLines <- stri_detect(tempFileStrings, regex = "\\s*@\\s*$")
if(sum(beginChunkLines)!=sum(endChunkLines)){
stop("Number of detected chunk beginnings different than number of detected chunk endings.")
} else if(sum(beginChunkLines) > 0){
chunkLinePairs <- cbind(which(beginChunkLines),which(endChunkLines))
sink(paste0("extractRChunks/RChunks/",commentedChunkNames, filename, "_RChunks",".R"))
for(i in 1:nrow(chunkLinePairs)){
chunkLabel <- stri_replace_all_regex(tempFileStrings[chunkLinePairs[i,1]],"(% ?)?<<(.+?),.*>>=","$2")
cat("##",chunkLabel)
cat("\n\n")
for(j in chunkLinePairs[i,1]:chunkLinePairs[i,2]){
cat(tempFileStrings[j])
cat("\n")
}
cat("\n\n")
}
sink()
} else {
message("No detected R chunks in ",filename,".Rnw. Aborting.")
}
}
chapterNames <- list.files("chapters", pattern="Rnw")
chapterNames <- stri_replace_all_fixed(chapterNames, ".Rnw", "")
for(i in chapterNames){
extractRChunks(i, includeCommentedChunks = FALSE)
extractRChunks(i, includeCommentedChunks = TRUE)
}
if (.Platform$OS.type=="unix") {
setwd("~/Dropbox/StatsBook6")
} else {# on a windows computer
setwd("C:/Users/xt8b/Dropbox/StatsBook6")
}
library(stringi)
# Only strips comments that start at the beginning of
# the line (other than spacing)
# If we try to delete mid-line LaTeX comments, we run into the problem
# of removing code like "%>%" and "%in%", which are important to keep.
# That said, I'm assuming code blocks that are commented out don't have
# LaTeX comments at the end of lines, and other LaTeX comments are
# being removed with the rest of the text anyway, so we don't need
# to worry about removing mid-line comments here
stripLaTeXComments <- function(vect){
vect <- stri_replace_all_regex(vect,"^\\s*%.*","")
return(vect)
}
extractRChunks <- function(filename, includeCommentedChunks = TRUE){
tempFileStrings <- readLines(paste0("chapters/",filename, ".Rnw"))
commentedChunkNames <- ""
if(!includeCommentedChunks){
tempFileStrings <- stripLaTeXComments(tempFileStrings)
commentedChunkNames <- "NoCommentedChunks_"
}
beginChunkLines <- stri_detect(tempFileStrings, regex = "<<.*>>=")
endChunkLines <- stri_detect(tempFileStrings, regex = "\\s*@\\s*$")
if(sum(beginChunkLines)!=sum(endChunkLines)){
stop("Number of detected chunk beginnings different than number of detected chunk endings.")
} else if(sum(beginChunkLines) > 0){
chunkLinePairs <- cbind(which(beginChunkLines),which(endChunkLines))
sink(paste0("extractRChunks/RChunks/",commentedChunkNames, filename, "_RChunks",".R"))
for(i in 1:nrow(chunkLinePairs)){
chunkLabel <- stri_replace_all_regex(tempFileStrings[chunkLinePairs[i,1]],"(% ?)?<<(.+?),.*>>=","$2")
chunkHeader <- stri_replace_all_regex(tempFileStrings[chunkLinePairs[i,1]],"(% ?)?<<|>>=","")
cat("##",chunkLabel,"\n")
cat("\n\n")
cat("```{r ",chunkHeader,"}\n",sep="")
for(j in (chunkLinePairs[i,1]+1):(chunkLinePairs[i,2]-1)){
cat(tempFileStrings[j])
cat("\n")
}
cat("```")
cat("\n\n")
}
sink()
} else {
message("No detected R chunks in ",filename,".Rnw. Aborting.")
}
}
chapterNames <- list.files("chapters", pattern="Rnw")
chapterNames <- stri_replace_all_fixed(chapterNames, ".Rnw", "")
for(i in chapterNames){
extractRChunks(i, includeCommentedChunks = FALSE)
extractRChunks(i, includeCommentedChunks = TRUE)
}
if (.Platform$OS.type=="unix") {
setwd("~/Dropbox/StatsBook6")
} else {# on a windows computer
setwd("C:/Users/xt8b/Dropbox/StatsBook6")
}
library(stringi)
# Only strips comments that start at the beginning of
# the line (other than spacing)
# If we try to delete mid-line LaTeX comments, we run into the problem
# of removing code like "%>%" and "%in%", which are important to keep.
# That said, I'm assuming code blocks that are commented out don't have
# LaTeX comments at the end of lines, and other LaTeX comments are
# being removed with the rest of the text anyway, so we don't need
# to worry about removing mid-line comments here
stripLaTeXComments <- function(vect){
vect <- stri_replace_all_regex(vect,"^\\s*%.*","")
return(vect)
}
extractRChunks <- function(filename, includeCommentedChunks = TRUE){
tempFileStrings <- readLines(paste0("chapters/",filename, ".Rnw"))
commentedChunkNames <- ""
if(!includeCommentedChunks){
tempFileStrings <- stripLaTeXComments(tempFileStrings)
commentedChunkNames <- "NoCommentedChunks_"
}
beginChunkLines <- stri_detect(tempFileStrings, regex = "<<.*>>=")
endChunkLines <- stri_detect(tempFileStrings, regex = "\\s*@\\s*$")
if(sum(beginChunkLines)!=sum(endChunkLines)){
stop("Number of detected chunk beginnings different than number of detected chunk endings.")
} else if(sum(beginChunkLines) > 0){
chunkLinePairs <- cbind(which(beginChunkLines),which(endChunkLines))
sink(paste0("extractRChunks/RChunks/",commentedChunkNames, filename, "_RChunks",".R"))
for(i in 1:nrow(chunkLinePairs)){
chunkLabel <- stri_replace_all_regex(tempFileStrings[chunkLinePairs[i,1]],"(% ?)?<<(.+?),.*>>=","$2")
chunkHeader <- stri_replace_all_regex(tempFileStrings[chunkLinePairs[i,1]],"(% ?)?<<|>>=","")
cat("##",chunkLabel)
cat("\n\n")
cat("```{r ",chunkHeader,"}\n",sep="")
for(j in (chunkLinePairs[i,1]+1):(chunkLinePairs[i,2]-1)){
cat(tempFileStrings[j])
cat("\n")
}
cat("```")
cat("\n\n")
}
sink()
} else {
message("No detected R chunks in ",filename,".Rnw. Aborting.")
}
}
chapterNames <- list.files("chapters", pattern="Rnw")
chapterNames <- stri_replace_all_fixed(chapterNames, ".Rnw", "")
for(i in chapterNames){
extractRChunks(i, includeCommentedChunks = FALSE)
extractRChunks(i, includeCommentedChunks = TRUE)
}
if (.Platform$OS.type=="unix") {
setwd("~/Dropbox/StatsBook6")
} else {# on a windows computer
setwd("C:/Users/xt8b/Dropbox/StatsBook6")
}
library(stringi)
# Only strips comments that start at the beginning of
# the line (other than spacing)
# If we try to delete mid-line LaTeX comments, we run into the problem
# of removing code like "%>%" and "%in%", which are important to keep.
# That said, I'm assuming code blocks that are commented out don't have
# LaTeX comments at the end of lines, and other LaTeX comments are
# being removed with the rest of the text anyway, so we don't need
# to worry about removing mid-line comments here
stripLaTeXComments <- function(vect){
vect <- stri_replace_all_regex(vect,"^\\s*%.*","")
return(vect)
}
extractRChunks <- function(filename, includeCommentedChunks = TRUE){
tempFileStrings <- readLines(paste0("chapters/",filename, ".Rnw"))
commentedChunkNames <- ""
if(!includeCommentedChunks){
tempFileStrings <- stripLaTeXComments(tempFileStrings)
commentedChunkNames <- "NoCommentedChunks_"
}
beginChunkLines <- stri_detect(tempFileStrings, regex = "<<.*>>=")
endChunkLines <- stri_detect(tempFileStrings, regex = "\\s*@\\s*$")
if(sum(beginChunkLines)!=sum(endChunkLines)){
stop("Number of detected chunk beginnings different than number of detected chunk endings.")
} else if(sum(beginChunkLines) > 0){
chunkLinePairs <- cbind(which(beginChunkLines),which(endChunkLines))
sink(paste0("extractRChunks/RChunks/",commentedChunkNames, filename, "_RChunks",".R"))
for(i in 1:nrow(chunkLinePairs)){
chunkLabel <- stri_replace_all_regex(tempFileStrings[chunkLinePairs[i,1]],"(% ?)?<<(.+?),.*>>=","$2")
chunkHeader <- stri_replace_all_regex(tempFileStrings[chunkLinePairs[i,1]],"(% ?)?<<|>>=","")
cat("##",chunkLabel)
cat("\n\n")
cat("```{r ",chunkHeader,"}\n",sep="")
for(j in (chunkLinePairs[i,1]+1):(chunkLinePairs[i,2]-1)){
cat(tempFileStrings[j])
cat("\n")
}
cat("```\n")
cat("\n\n")
}
sink()
} else {
message("No detected R chunks in ",filename,".Rnw. Aborting.")
}
}
chapterNames <- list.files("chapters", pattern="Rnw")
chapterNames <- stri_replace_all_fixed(chapterNames, ".Rnw", "")
for(i in chapterNames){
extractRChunks(i, includeCommentedChunks = FALSE)
extractRChunks(i, includeCommentedChunks = TRUE)
}
list.files("extractRChunks/RChunks")
library(remotes)
?install_github
devtools::document()
#' Calculate a folded log  with the Tukey and Haldane-Anscombe corrections
#'
#' @param bayesFactor
#' @return The g-prior associated with the inputted Bayes factor
#' @export
ANOVA_overlay <- function(dv, iv, data, common = mean){
data <- data[,c(dv, iv)]
data.w <- unstack(data, formula(paste0(dv, "~", iv)))
maxN_Group <- max(sapply(data.w, length))
data.w <- as.data.frame(sapply(data.w, function(x){
if(length(x) < maxN_Group){
return(c(x,rep(NA, maxN_Group-length(x))))
}
return(x)
}))
# Split the mood data into overlays
data.mn <- sapply(data.w, common, na.rm = TRUE)
# sweep:
dataResid <- sweep(data.w, MARGIN = 2, STATS = data.mn)
#taking a value, and subtracting it from
#all of the values in an overlay to get another overlay
# common
dataCommon <- common(data.mn, na.rm = TRUE)
# sweep common out condition means to get the effect of condition
data.eff <- data.mn - dataCommon
# turn into four overlays
# (1) data
data.w
# (2) common
dataCommonOverlay <- as.data.frame(matrix(dataCommon, nrow = nrow(data.w),
ncol = ncol(data.w)))
names(dataCommonOverlay) <- names(data.eff)
# (3) condition
dataOverlay <- as.data.frame(matrix(data.mn, nrow = nrow(data.w),
ncol = ncol(data.w),
byrow = TRUE))
names(dataOverlay) <- names(data.mn)
# (4) residuals
names(dataResid) <- names(data.mn)
return(list("data"=tibble::tibble(data.w),
"common"=tibble::tibble(dataCommonOverlay),
"condition"=tibble::tibble(dataOverlay),
"residuals"=tibble::tibble(dataResid)))
}
ANOVA_overlay("wt", "am", mtcars)
ANOVA_overlay("wt", "am", mtcars, common = median)
library(roxygen2)
install.packages("roxygen2")
library(roxygen2)
roxygen2::roxygenise()
roxygen2::roxygenise()
rm(list = c("ANOVA_overlay"))
roxygen2::roxygenise()
install.packages("vcd")
roxygen2::roxygenise()
library(magrittr)
pip
pipe
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
#'\dontrun{
#' # using tapply to see the data split by condition, assuming a mean common
#' tapply(mtcars$wt,mtcars$am,mean)
#'
#' # using ANOVA_overlay
#' ANOVA_overlay("wt", "am", mtcars)
#' ANOVA_overlay("wt", "am", mtcars, common = median)
#' ANOVA_overlay("wt", "gear", mtcars)
#'}
#' @export
ANOVA_overlay <- function(dv, iv, data, common = mean){
data <- data[,c(dv, iv)]
data.w <- unstack(data, formula(paste0(dv, "~", iv)))
maxN_Group <- max(sapply(data.w, length))
data.w <- as.data.frame(sapply(data.w, function(x){
if(length(x) < maxN_Group){
return(c(x,rep(NA, maxN_Group-length(x))))
}
return(x)
}))
# Split the mood data into overlays
data.mn <- sapply(data.w, common, na.rm = TRUE)
# sweep:
dataResid <- sweep(data.w, MARGIN = 2, STATS = data.mn)
#taking a value, and subtracting it from
#all of the values in an overlay to get another overlay
# common
dataCommon <- common(data.mn, na.rm = TRUE)
# sweep common out condition means to get the effect of condition
data.eff <- data.mn - dataCommon
# turn into four overlays
# (1) data
data.w
# (2) common
dataCommonOverlay <- as.data.frame(matrix(dataCommon, nrow = nrow(data.w),
ncol = ncol(data.w)))
names(dataCommonOverlay) <- names(data.eff)
# (3) condition
dataOverlay <- as.data.frame(matrix(data.mn, nrow = nrow(data.w),
ncol = ncol(data.w),
byrow = TRUE))
names(dataOverlay) <- names(data.mn)
# (4) residuals
names(dataResid) <- names(data.mn)
return(list("data"=tibble::tibble(data.w),
"common"=tibble::tibble(dataCommonOverlay),
"condition"=tibble::tibble(dataOverlay),
"residuals"=tibble::tibble(dataResid)))
}
ANOVA_overlay("wt", "am", mtcars)
?sweep
?common
roxygen2::roxygenise()
rm(list = c("ANOVA_overlay"))
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
update.packages()
remotes::install_github("mjmeyer111/DARE")
